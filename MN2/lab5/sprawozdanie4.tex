\documentclass[]{article}
\usepackage{polski}
\usepackage[utf8]{inputenc}
\usepackage{mathtools}
\usepackage{pgfplots}
\usepackage{listings}
\usepackage{enumitem}
\usepackage{mathtools}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{pgf,tikz}
\usepackage{mathrsfs}
\usetikzlibrary{arrows}
%opening
\let\normalint\int % PS
\def\int{\displaystyle\normalint} %PS
\title{\textbf{ Metody Numeryczne 2\\Laboratorium 5}\\
Obliczanie wskaźnika uwarunkowania macierzy $A=A^T$ i diagonalnie silnie dominującej }
\author{Szymon Adach}

\begin{document}

\maketitle

\section{Treść zadania}
 \textbf{Zadanie 6:} Obliczanie wskaźnika uwarunkowania macierzy $A=A^T$ i diagonalnie silnie dominującej ($cond_2(A)=\frac{ \lambda_{max}}{ \lambda_{min}}$). Do obliczenia $ \lambda_{max}$ należy zastosować zwyklą metodę potegową, a do obliczenia $\lambda_{min}$ odwrotną metodę potegową. Odpowiedni układ równań należy rozwiązać metodą iteracyjną Jacobiego.
\section{Opis metody}
 $\lambda_{max}$ obliczana jest za pomocą prostej metody potęgowej. Aby wyeliminować nadmiar bądź niedomiar zastosowano normowanie wektora $x$. Algorytm znajdowania tej wartości własnej macierzy $A$ przedstawia się następująco:
 \begin{center}
 	$\begin{cases} 
 	x^{(0)} \neq 0 \\
 	x^{(k+1)} = A\cdot x^{(k)}$ dla $k = 0,1\dots n\\
 	\end{cases}$
\end{center}
Ponadto w każdej iteracji wykonywane jest normowanie wektora $x$:
\begin{center}
	$x^{(k+1)} = \frac{x^{(k+1)}} {\lVert x^{(k+1)}\rVert_2}$
\end{center}
Wektor $x^{(0)}$ jest losowany podczas uruchamiania programu. Końcowy wynik obliczany jest ze wzoru:
\begin{center}
	$\lambda_{max} = \frac{(Ax, x)}{\lVert x^{(k+1)}\rVert_2}$
\end{center}
\newpage
 $\lambda_{min}$ obliczana jest za pomocą odwrotnej metody potęgowej. Algorytm znajdowania tej wartości własnej macierzy $A$ przedstawia się następująco:
 \begin{center}
 	$\begin{cases} 
 	\lambda^{*} \approx \lambda_i\\
 	x^{(0)} \neq 0 \\
 	(A - \lambda^{*}I)y^{(k+1)} = x^{(k)}\\
 	\lambda_{i}^{(k)} = \frac{1}{(y^{(k+1)}, x^{(k)})} - \lambda^{*} \\
 	x^{(k+1)} = \frac{y^{(k+1)}}{\lVert(y^{(k+1)}\rVert_2}\\
 	\end{cases}$
 \end{center}
Wektor $x^{(0)}$ jest losowany podczas uruchamiania programu. Równanie ($A - \lambda^{*}I)y^{(k+1)} = x^{(k)}$ rozwiązywane jest za pomocą metody iteracyjnej Jacobiego z zadaną dokładnością.
\section{Działanie programu}

Program jest uruchamiany poleceniem:
\begin{center}
	\textbf{conditional\_number(A, n, e)}
\end{center} 
\begin{itemize}
	\item \textbf{A} - macierz, której wskaźnik uwarunkowania zostanie obliczony
	\item \textbf{n} - liczba iteracji w metodach potęgowej i odwrotnej potęgowej
	\item \textbf{e} - błąd bezwzględny metody Jacobiego rozwiązywania równania \\$(A - \lambda^{*}I)y^{(k+1)} = x^{(k)}$ w odwrotnej metodzie potęgowej
\end{itemize}
Po wykonaniu obliczeń prezentowane są wartości $\lambda_{max}$, $\lambda_{min}$ oraz $cond_2(A)$:\\
\verb|Lambda_min = |\\
\verb|Lambda_max = |\\
\verb|cond_2(A) = |
\section{Przykłady}
\begin{enumerate}
\item \textbf{Wywołanie:}\\
$A = \begin{bmatrix}
4 & 1 & 0\\
1 & 4 & 1\\
0 & 1 & 4
\end{bmatrix}$\\
\verb|condition_number(A, 100, 0.001)|
\\\textbf{Wyjście:}\\
\verb|Lambda_min = 2.588539|\\
\verb|Lambda_max = 5.414214|\\
\verb|cond_2(A) = 2.091610|\\
\textbf{eig(A)} =  2.5858 4.0000 5.4142\\
\textbf{Obserwacja:} Dla tego problemu podobny wpływ na dokładność programu ma zwiększenie liczby iteracji oraz zmniejszenie dopuszczalnego błędu metody Jacobiego.
\item \textbf{Wywołanie:} \verb|aproksymacja(@(x)x^6+5*x^5, 10, 7)|
\\\textbf{Wyjście:}
    
\item \textbf{Wywołanie:} \verb|aproksymacja(@cos, 10, 4)|
\\\textbf{Wyjście:}\\

\end{enumerate}
\end{document}
